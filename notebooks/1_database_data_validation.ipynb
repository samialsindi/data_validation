{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Database data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook, we will see how we can use the great_expectations package to validate data in our database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NatanMish/data_validation/blob/main/notebooks/1_database_data_validation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Install the required packages and import them to the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting great_expectations\n",
      "  Using cached great_expectations-0.15.10-py3-none-any.whl (5.1 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp38-cp38-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "Collecting pyparsing<3,>=2.4\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting nbformat>=5.0\n",
      "  Using cached nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
      "Collecting tqdm>=4.59.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting tzlocal>=1.2\n",
      "  Using cached tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting mistune>=0.8.4\n",
      "  Using cached mistune-2.0.2-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from great_expectations) (2.8.2)\n",
      "Collecting colorama>=0.4.3\n",
      "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting jsonschema>=2.5.1\n",
      "  Using cached jsonschema-4.6.0-py3-none-any.whl (80 kB)\n",
      "Collecting pytz>=2021.3\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting importlib-metadata>=1.7.0\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting altair<5,>=4.0.0\n",
      "  Using cached altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "Collecting typing-extensions>=3.10.0.0\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting numpy>=1.14.1\n",
      "  Using cached numpy-1.22.4-cp38-cp38-macosx_10_15_x86_64.whl (17.6 MB)\n",
      "Collecting Click>=7.1.2\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting scipy>=0.19.0\n",
      "  Downloading scipy-1.8.1-cp38-cp38-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 55.3 MB 836 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Ipython>=7.16.3 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from great_expectations) (8.3.0)\n",
      "Collecting jsonpatch>=1.22\n",
      "  Using cached jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jinja2<3.1.0,>=2.10\n",
      "  Using cached Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting cryptography>=3.2\n",
      "  Using cached cryptography-37.0.2-cp36-abi3-macosx_10_10_x86_64.whl (2.8 MB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting ruamel.yaml<0.17.18,>=0.16\n",
      "  Using cached ruamel.yaml-0.17.17-py3-none-any.whl (109 kB)\n",
      "Collecting notebook>=6.4.10\n",
      "  Using cached notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
      "Requirement already satisfied: entrypoints in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from altair<5,>=4.0.0->great_expectations) (0.4)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 7.1 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting cffi>=1.12\n",
      "  Downloading cffi-1.15.0-cp38-cp38-macosx_10_9_x86_64.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=0.5\n",
      "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (2.11.2)\n",
      "Requirement already satisfied: backcall in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.2.0)\n",
      "Requirement already satisfied: appnope in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.1.2)\n",
      "Requirement already satisfied: decorator in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (61.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from Ipython>=7.16.3->great_expectations) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from jedi>=0.16->Ipython>=7.16.3->great_expectations) (0.8.3)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp38-cp38-macosx_10_9_universal2.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 7.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting attrs>=17.4.0\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 7.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: jupyter-core in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from nbformat>=5.0->great_expectations) (4.10.0)\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.15.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from notebook>=6.4.10->great_expectations) (6.1)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from notebook>=6.4.10->great_expectations) (7.2.2)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from notebook>=6.4.10->great_expectations) (1.5.5)\n",
      "Collecting nbconvert>=5\n",
      "  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
      "\u001b[K     |████████████████████████████████| 561 kB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.15.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from notebook>=6.4.10->great_expectations) (22.3.0)\n",
      "Requirement already satisfied: ipykernel in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from notebook>=6.4.10->great_expectations) (6.9.1)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting mistune>=0.8.4\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.6.4-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 803 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach\n",
      "  Downloading bleach-5.0.0-py3-none-any.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting traitlets>=5\n",
      "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess>=0.5 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from pexpect>4.3->Ipython>=7.16.3->great_expectations) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython>=7.16.3->great_expectations) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from python-dateutil>=2.8.1->great_expectations) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from requests>=2.20->great_expectations) (2022.5.18.1)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 23.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp38-cp38-macosx_10_9_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-macosx_10_14_x86_64.whl (35 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 841 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from ipykernel->notebook>=6.4.10->great_expectations) (1.5.1)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
      "\u001b[K     |████████████████████████████████| 339 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pure-eval in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from stack-data->Ipython>=7.16.3->great_expectations) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from stack-data->Ipython>=7.16.3->great_expectations) (2.0.5)\n",
      "Requirement already satisfied: executing in /Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages (from stack-data->Ipython>=7.16.3->great_expectations) (0.8.3)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=16f9051ab207fb7f86cec4d774691df672f2f06da0a61ccb591d58306b742c1b\n",
      "  Stored in directory: /Users/samia/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: zipp, traitlets, pyrsistent, importlib-resources, attrs, pycparser, jsonschema, fastjsonschema, webencodings, soupsieve, pyparsing, nbformat, MarkupSafe, cffi, tzdata, tinycss2, pytz, pandocfilters, packaging, numpy, nbclient, mistune, jupyterlab-pygments, jinja2, defusedxml, bleach, beautifulsoup4, backports.zoneinfo, argon2-cffi-bindings, urllib3, toolz, terminado, Send2Trash, ruamel.yaml.clib, pytz-deprecation-shim, prometheus-client, pandas, nbconvert, jsonpointer, ipython-genutils, idna, charset-normalizer, argon2-cffi, tzlocal, typing-extensions, tqdm, termcolor, scipy, ruamel.yaml, requests, notebook, jsonpatch, importlib-metadata, cryptography, colorama, Click, altair, great-expectations\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "Successfully installed Click-8.1.3 MarkupSafe-2.1.1 Send2Trash-1.8.0 altair-4.2.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-21.4.0 backports.zoneinfo-0.2.1 beautifulsoup4-4.11.1 bleach-5.0.0 cffi-1.15.0 charset-normalizer-2.0.12 colorama-0.4.5 cryptography-37.0.2 defusedxml-0.7.1 fastjsonschema-2.15.3 great-expectations-0.15.10 idna-3.3 importlib-metadata-4.11.4 importlib-resources-5.8.0 ipython-genutils-0.2.0 jinja2-3.0.3 jsonpatch-1.32 jsonpointer-2.3 jsonschema-4.6.0 jupyterlab-pygments-0.2.2 mistune-0.8.4 nbclient-0.6.4 nbconvert-6.5.0 nbformat-5.4.0 notebook-6.4.12 numpy-1.22.4 packaging-21.3 pandas-1.4.2 pandocfilters-1.5.0 prometheus-client-0.14.1 pycparser-2.21 pyparsing-2.4.7 pyrsistent-0.18.1 pytz-2022.1 pytz-deprecation-shim-0.1.0.post0 requests-2.28.0 ruamel.yaml-0.17.17 ruamel.yaml.clib-0.2.6 scipy-1.8.1 soupsieve-2.3.2.post1 termcolor-1.1.0 terminado-0.15.0 tinycss2-1.1.1 toolz-0.11.2 tqdm-4.64.0 traitlets-5.3.0 typing-extensions-4.2.0 tzdata-2022.1 tzlocal-4.2 urllib3-1.26.9 webencodings-0.5.1 zipp-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U great_expectations pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import great_expectations as ge\n",
    "from ruamel import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Great Expectations](https://docs.greatexpectations.io/img/great-expectations-long-logo.svg)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Named after the famous 19th century novel, Great Expectations is a shared, open sourced package for data quality. It helps eliminate pipeline debt, through data testing, documentation, and profiling. It is a tool for data scientists, data engineers, and data analysts to validate data. GE has many useful integrations and can be connected directly to SQL databases, Apache Spark, Apache Airflow, Bigquery, and more. In this tutorial, we will validate a database hosted on a  local file system, but the process for a cloud file system such as a Data Lake, Azure Blob Storage, GCP bucket or AWS S3 is almost identical.\n",
    "\n",
    "**Terminology**\n",
    "1. *Data Context* - The primary entry point for a Great Expectations deployment, with configurations and methods for all supporting components.\n",
    "\n",
    "2. *Data Source* - Provides a standard API for accessing and interacting with data from a wide variety of source systems.\n",
    "\n",
    "3. *Data Asset* - A collection of records within a Datasource which is usually named based on the underlying data system and sliced to correspond to a desired specification.\n",
    "\n",
    "4. *Expectation Suite* - A collection of verifiable assertions about data.\n",
    "\n",
    "5. *Validation* - The act of applying an Expectation Suite to a Batch.\n",
    "\n",
    "6. *Batch Identifier* - contains information that uniquely identifies a specific batch from the Data Asset, such as the delivery date or query time.\n",
    "\n",
    "7. *Data Connector* - Provides the configuration details based on the source data system which are needed by a Datasource to define Data Assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Create a Data Context\n",
    "\n",
    "We will now create a data context, which is the first step in setting up Great Expectations for our project. Creating a data context is actually most easily done in bash using the great_expectations CLI. Run the shell command below and this will initialize a new data context in the current directory. The `echo y` bit is used to suppress the interactive prompt. You will now see a new directory called `great_expectations` created in your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using v3 (Batch Request) API\u001b[0m\n",
      "\u001b[36m\n",
      "  ___              _     ___                  _        _   _\n",
      " / __|_ _ ___ __ _| |_  | __|_ ___ __  ___ __| |_ __ _| |_(_)___ _ _  ___\n",
      "| (_ | '_/ -_) _` |  _| | _|\\ \\ / '_ \\/ -_) _|  _/ _` |  _| / _ \\ ' \\(_-<\n",
      " \\___|_| \\___\\__,_|\\__| |___/_\\_\\ .__/\\___\\__|\\__\\__,_|\\__|_\\___/_||_/__/\n",
      "                                |_|\n",
      "             ~ Always know what to expect from your data ~\n",
      "\u001b[0m\u001b[0m\n",
      "Let's create a new Data Context to hold your project configuration.\n",
      "\n",
      "Great Expectations will create a new directory with the following structure:\n",
      "\n",
      "    great_expectations\n",
      "    |-- great_expectations.yml\n",
      "    |-- expectations\n",
      "    |-- checkpoints\n",
      "    |-- plugins\n",
      "    |-- .gitignore\n",
      "    |-- uncommitted\n",
      "        |-- config_variables.yml\n",
      "        |-- data_docs\n",
      "        |-- validations\n",
      "\n",
      "OK to proceed? [Y/n]: \n",
      "================================================================================\n",
      "\u001b[0m\n",
      "\u001b[36mCongratulations! You are now ready to customize your Great Expectations configuration.\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[36mYou can customize your configuration in many ways. Here are some examples:\u001b[0m\n",
      "\n",
      "  \u001b[36mUse the CLI to:\u001b[0m\n",
      "    - Run `\u001b[32mgreat_expectations datasource new\u001b[0m` to connect to your data.\n",
      "    - Run `\u001b[32mgreat_expectations checkpoint new <checkpoint_name>\u001b[0m` to bundle data with Expectation Suite(s) in a Checkpoint for later re-validation.\n",
      "    - Run `\u001b[32mgreat_expectations suite --help\u001b[0m` to create, edit, list, profile Expectation Suites.\n",
      "    - Run `\u001b[32mgreat_expectations docs --help\u001b[0m` to build and manage Data Docs sites.\n",
      "\n",
      "  \u001b[36mEdit your configuration in great_expectations.yml to:\u001b[0m\n",
      "    - Move Stores to the cloud\n",
      "    - Add Slack notifications, PagerDuty alerts, etc.\n",
      "    - Customize your Data Docs\n",
      "\n",
      "\u001b[36mPlease see our documentation for more configuration options!\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!echo y | great_expectations init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the init command, your great_expectations directory will contain all the important components of a local Great Expectations deployment. This is what the directory structure looks like:\n",
    "\n",
    "- `great_expectations.yml` contains the main configuration of your deployment.\n",
    "The expectations directory stores all your Expectations as JSON files. If you want to store them somewhere else, you can change that later.\n",
    "\n",
    "- The `plugins/` directory holds code for any custom plugins you develop as part of your deployment.\n",
    "\n",
    "- The `uncommitted/` directory contains files that shouldn’t live in version control. It has a .gitignore configured to exclude all its contents from version control. The main contents of the directory are:\n",
    "    1. `uncommitted/config_variables.yml`, which holds sensitive information, such as database credentials and other secrets.\n",
    "    2. `uncommitted/data_docs`, which contains Data Docs generated from Expectations, Validation Results, and other metadata.\n",
    "    3. `uncommitted/validations`, which holds Validation Results generated by Great Expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"https://docs.greatexpectations.io/assets/images/data_context_does_for_you-df2eca32d0152ead16cccd5d3d226abb.png\" width=\"1000\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Create a Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will start by reading in the GE data context we have created in the previous step\n",
    "context = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we will script a yaml file to create a data source. We will need the following configuration parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasource_name = \"house_prices\"\n",
    "# Data Source - Provides a standard API for accessing and interacting with data from a wide variety of source systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution_engine = \"PandasExecutionEngine\"  # alternatively we can use SparkExecutionEngine for PySpark oriented\n",
    "# projects or SqlAlchemyExecutionEngine for creating a SQL database data source.\n",
    "data_directory = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_asset_name = f\"{datasource_name}_survey_2006\"\n",
    "# Data Asset - A collection of records within a Datasource which is usually named based on the underlying data system and sliced to correspond to a desired specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runtime_data_connector_name = \"runtime_batch_files_connector\"\n",
    "# Data Connector - Provides the configuration details based on the source data system which are needed by a Datasource to define Data Assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasource_config = {\n",
    "    \"name\": datasource_name,\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": execution_engine,\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        runtime_data_connector_name: {\n",
    "            \"class_name\": \"RuntimeDataConnector\",\n",
    "            \"batch_identifiers\": [\"default_identifier_name\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\truntime_batch_files_connector:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samia/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages/great_expectations/datasource/data_connector/runtime_data_connector.py:133: DeprecationWarning: Specifying batch_identifiers as part of the RuntimeDataConnector config is deprecated as of v0.15.1 and will be removed by v0.18. Please configure batch_identifiers as part of Assets instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7fb438984ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the configuration is valid\n",
    "context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7fb4389eec10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the configuration is valid, we can create the datasource\n",
    "context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data_connectors': {'runtime_batch_files_connector': {'module_name': 'great_expectations.datasource.data_connector',\n",
       "    'class_name': 'RuntimeDataConnector',\n",
       "    'batch_identifiers': ['default_identifier_name']}},\n",
       "  'module_name': 'great_expectations.datasource',\n",
       "  'class_name': 'Datasource',\n",
       "  'execution_engine': {'module_name': 'great_expectations.execution_engine',\n",
       "   'class_name': 'PandasExecutionEngine'},\n",
       "  'name': 'house_prices'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can see that the datasource was created.\n",
    "context.list_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Create an Expectation Suite\n",
    "Expectations are the core of Great Expectations. They are the assertions that are used to validate data. Let's create an expectation suite which is a collection of expectations. This diagram below shows how we can define good expectations for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"https://docs.greatexpectations.io/assets/images/where_expectations_come_from-b3504cf51ad304c8e4a73677a0e73156.png\" width=\"1000\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will create expectations while exploring the data in the notebook. The method below behaves  exactly the same as `pandas.read_csv`. Similarly wrapped versions of other pandas methods (`read_excel`, `read_table`, `read_parquet`, `read_pickle`, `read_json`, etc.) are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "home_data = ge.read_csv(\"https://github.com/NatanMish/data_validation/blob/a77b247b25c6622ce0c8f8cbc505228161c31a3c/data/train.csv?raw=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The home_data variable is a pandas dataframe with all the methods and properties we know and love. We can use the `head` method to see the\n",
    "# first few rows of the data.\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# beyond the Pandas methods and properties, we can use GE's expectations methods to define expectations. \n",
    "# In Jupyter, type in `home_data.expect` and press tab to see the list of available expectations.\n",
    "# home_data.expect\n",
    "\n",
    "home_data.expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {},\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a few example expectations and see if they are valid on this dataset.\n",
    "home_data.expect_column_to_exist(\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice the `\"success\": true` key in the result dictionary, this means the expectation is valid for this data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"element_count\": 1460,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"unexpected_percent_nonmissing\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.expect_column_values_to_be_unique(\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The expectation above checked the contents of the column, hence we got a few other useful metrics, showing how many \n",
    "rows were inspected, how many were missing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"result\": {\n",
       "    \"observed_value\": 755000,\n",
       "    \"element_count\": 1460,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This expectation should fail, lets see what happens:\n",
    "home_data.expect_column_max_to_be_between(\"SalePrice\", 0, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The returned dictionary shows that the expectation is not valid, and the value observed that is not in the expected range.\n",
    "Here are a few more useful expectation definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%% mdhhome_data.expect_column_distinct_values_to_be_in_set\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"C (all)\",\n",
       "      \"FV\",\n",
       "      \"RH\",\n",
       "      \"RL\",\n",
       "      \"RM\"\n",
       "    ],\n",
       "    \"element_count\": 1460,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.expect_column_distinct_values_to_be_in_set(\"MSZoning\", [\"C (all)\", \"FV\", \"RH\", \"RL\", \"RM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": 1515.463698630137,\n",
       "    \"element_count\": 1460,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.expect_column_mean_to_be_between(\"GrLivArea\", 0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"expectation_suite_name\": \"default\",\n",
       "  \"ge_cloud_id\": null,\n",
       "  \"expectations\": [\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Id\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_column_to_exist\"\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"Id\"\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_column_values_to_be_unique\"\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"MSZoning\",\n",
       "        \"value_set\": [\n",
       "          \"C (all)\",\n",
       "          \"FV\",\n",
       "          \"RH\",\n",
       "          \"RL\",\n",
       "          \"RM\"\n",
       "        ]\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\"\n",
       "    },\n",
       "    {\n",
       "      \"kwargs\": {\n",
       "        \"column\": \"GrLivArea\",\n",
       "        \"min_value\": 0,\n",
       "        \"max_value\": 10000\n",
       "      },\n",
       "      \"meta\": {},\n",
       "      \"expectation_type\": \"expect_column_mean_to_be_between\"\n",
       "    }\n",
       "  ],\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.15.10\"\n",
       "  },\n",
       "  \"data_asset_type\": \"Dataset\"\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will create an expectation suite from all the valid expectations we created above.\n",
    "home_data.get_expectation_suite()\n",
    "# If we want the non-valid expectations as well, we can use the `get_expectation_suite` method with the \n",
    "# `discard_failed_expectations` parameter set to True. If there are any duplicate expectations in the suite, \n",
    "# the duplicates will be discarded:\n",
    "# home_data.get_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samia/Downloads/PyDataLondon2022/Friday_TS2_0900/notebooks/great_expectations/expectations/my_expectations.json'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line will save the expectation suite to the data context\n",
    "context.save_expectation_suite(home_data.get_expectation_suite(), \"my_expectations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PandasDataset' object has no attribute 'expect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/samia/Downloads/PyDataLondon2022/Friday_TS2_0900/notebooks/1_database_data_validation.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samia/Downloads/PyDataLondon2022/Friday_TS2_0900/notebooks/1_database_data_validation.ipynb#ch0000058?line=0'>1</a>\u001b[0m home_data\u001b[39m.\u001b[39;49mexpect\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pydatalondon2022/lib/python3.8/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PandasDataset' object has no attribute 'expect'"
     ]
    }
   ],
   "source": [
    "home_data.expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 1\n",
    "Check the following expectations to see if they are valid on the home_data dataframe:\n",
    "\n",
    "(Not all the expectations were included in the examples above. You can find more expectations in the [expectations directory](https://greatexpectations.io/expectations).)\n",
    "1. `Street` column should be a string.\n",
    "2. `LandContour` column cannot be null.\n",
    "3. `YearBuilt` minimal value should be between 1700 and 1900.\n",
    "4. `LotArea` median value should be between 5000 and 15000.\n",
    "5. The most common values in `SaleType` must be either `WD` or `New`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"WD\"\n",
       "    ],\n",
       "    \"element_count\": 1460,\n",
       "    \"missing_count\": null,\n",
       "    \"missing_percent\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answers here:\n",
    "#home_data.expect_column_values_to_be_of_type('Street', 'str')\n",
    "#home_data.expect_column_values_to_not_be_null('LandContour')\n",
    "\n",
    "# home_data.expect_column_values_to_be_between('YearBuilt', 1700, 1900)\n",
    "\n",
    "\n",
    "# home_data.expect_column_median_to_be_between('LotArea', 5000, 15000)\n",
    "# home_data.expect_column_median_to_be_between('LotArea', 5000, 15000)\n",
    "home_data.expect_column_most_common_value_to_be_in_set('SaleType', [\"WD\", \"New\"])\n",
    "\n",
    "#most common value to be in set, 'salestype, [\"t\", \"3\"]\n",
    "# home_data.expec\n",
    "# home_data.ex\n",
    "#home_data.exp\n",
    "# home_data.expect_column_\n",
    "# home_data.expect_column_\n",
    "# home_data.expect_column_\n",
    "# home_data.expect_column_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Exercise solutions can be found in the exercise solutions file in the current directory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Validate the Data\n",
    "We will now validate the test data using the expectations we have created for the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"data_batch_appended\"\n",
    "# Checkpoint - The primary means for validating data in a production deployment of Great Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"action_list\": [\n",
       "    {\n",
       "      \"name\": \"store_validation_result\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreValidationResultAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"store_evaluation_params\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"update_data_docs\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"UpdateDataDocsAction\",\n",
       "        \"site_names\": []\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"batch_request\": {},\n",
       "  \"class_name\": \"Checkpoint\",\n",
       "  \"config_version\": 1.0,\n",
       "  \"evaluation_parameters\": {},\n",
       "  \"module_name\": \"great_expectations.checkpoint\",\n",
       "  \"name\": \"data_batch_appended\",\n",
       "  \"profilers\": [],\n",
       "  \"runtime_configuration\": {},\n",
       "  \"validations\": [\n",
       "    {\n",
       "      \"batch_request\": {\n",
       "        \"datasource_name\": \"house_prices\",\n",
       "        \"data_connector_name\": \"runtime_batch_files_connector\",\n",
       "        \"data_asset_name\": \"house_prices_survey_2006\"\n",
       "      },\n",
       "      \"expectation_suite_name\": \"my_expectations\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": checkpoint_name,\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": {\n",
    "                \"datasource_name\": datasource_name,\n",
    "                \"data_connector_name\": runtime_data_connector_name,\n",
    "                \"data_asset_name\": data_asset_name,\n",
    "            },\n",
    "            \"expectation_suite_name\": \"my_expectations\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking at the dictionary returned by the `add_checkpoint` methods we can see what are the actions performed every time the checkpoint will run:\n",
    "1. Store validation result.\n",
    "2. Store evaluation parameters.\n",
    "3. Update data docs. (we will look at the data docs later in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "home_data_test = pd.read_csv(\"https://github.com/NatanMish/data_validation/blob/a77b247b25c6622ce0c8f8cbc505228161c31a3c/data/test.csv?raw=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 10/10 [00:00<00:00, 465.88it/s]\n"
     ]
    }
   ],
   "source": [
    "results = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    batch_request={\n",
    "        \"runtime_parameters\": {\"batch_data\": home_data_test},\n",
    "        \"batch_identifiers\": {\n",
    "            \"default_identifier_name\": \"default_identifier_name\"\n",
    "        },\n",
    "    },\n",
    ")\n",
    "# Batch Identifier - contains information that uniquely identifies a specific batch from the Data Asset, such as the delivery date or query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluated_expectations': 4,\n",
       " 'successful_expectations': 4,\n",
       " 'unsuccessful_expectations': 0,\n",
       " 'success_percent': 100.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the validation result object we got:\n",
    "run_identifier = next(iter(results['run_results']))\n",
    "results['run_results'][run_identifier]['validation_result']['statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"result\": {\n",
       "    \"observed_value\": [\n",
       "      \"C (all)\",\n",
       "      \"FV\",\n",
       "      \"RH\",\n",
       "      \"RL\",\n",
       "      \"RM\"\n",
       "    ],\n",
       "    \"details\": {\n",
       "      \"value_counts\": [\n",
       "        {\n",
       "          \"value\": \"C (all)\",\n",
       "          \"count\": 15\n",
       "        },\n",
       "        {\n",
       "          \"value\": \"FV\",\n",
       "          \"count\": 74\n",
       "        },\n",
       "        {\n",
       "          \"value\": \"RH\",\n",
       "          \"count\": 10\n",
       "        },\n",
       "        {\n",
       "          \"value\": \"RL\",\n",
       "          \"count\": 1114\n",
       "        },\n",
       "        {\n",
       "          \"value\": \"RM\",\n",
       "          \"count\": 242\n",
       "        }\n",
       "      ]\n",
       "    }\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of one of the validations on one of the expectations. The check has passed and there are some \n",
    "# useful extra details too.\n",
    "results['run_results'][run_identifier]['validation_result']['results'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### How does an invalid data checkpoint look like?\n",
    "Glad you asked, let's inject a duplicate value to our `Id` column to see how it behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This will create a duplicate id value for two separate records\n",
    "home_data_test.at[0, 'Id'] = 1462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"action_list\": [\n",
       "    {\n",
       "      \"name\": \"store_validation_result\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreValidationResultAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"store_evaluation_params\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"update_data_docs\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"UpdateDataDocsAction\",\n",
       "        \"site_names\": []\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"batch_request\": {},\n",
       "  \"class_name\": \"Checkpoint\",\n",
       "  \"config_version\": 1.0,\n",
       "  \"evaluation_parameters\": {},\n",
       "  \"module_name\": \"great_expectations.checkpoint\",\n",
       "  \"name\": \"my_bad_data_checkpoint\",\n",
       "  \"profilers\": [],\n",
       "  \"runtime_configuration\": {},\n",
       "  \"validations\": [\n",
       "    {\n",
       "      \"batch_request\": {\n",
       "        \"datasource_name\": \"house_prices\",\n",
       "        \"data_connector_name\": \"runtime_batch_files_connector\",\n",
       "        \"data_asset_name\": \"batch_data_asset\"\n",
       "      },\n",
       "      \"expectation_suite_name\": \"my_expectations\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data_checkpoint_name = \"my_bad_data_checkpoint\"\n",
    "bad_data_checkpoint_config = {\n",
    "    \"name\": bad_data_checkpoint_name,\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": {\n",
    "                \"datasource_name\": datasource_name,\n",
    "                \"data_connector_name\": runtime_data_connector_name,\n",
    "                \"data_asset_name\": \"batch_data_asset\",\n",
    "            },\n",
    "            \"expectation_suite_name\": \"my_expectations\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "context.add_checkpoint(**bad_data_checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 10/10 [00:00<00:00, 685.93it/s]\n"
     ]
    }
   ],
   "source": [
    "results_bad_data_checkpoint = context.run_checkpoint(\n",
    "    checkpoint_name=bad_data_checkpoint_name,\n",
    "    batch_request={\n",
    "        \"runtime_parameters\": {\"batch_data\": home_data_test},\n",
    "        \"batch_identifiers\": {\n",
    "            \"default_identifier_name\": \"default_identifier_name\"\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluated_expectations': 4,\n",
       " 'successful_expectations': 3,\n",
       " 'unsuccessful_expectations': 1,\n",
       " 'success_percent': 75.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As expected, not all expectations were successful.\n",
    "bad_data_run_identifier = next(iter(results_bad_data_checkpoint['run_results']))\n",
    "results_bad_data_checkpoint['run_results'][bad_data_run_identifier]['validation_result']['statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"result\": {\n",
       "    \"element_count\": 1459,\n",
       "    \"unexpected_count\": 2,\n",
       "    \"unexpected_percent\": 0.1370801919122687,\n",
       "    \"partial_unexpected_list\": [\n",
       "      1462,\n",
       "      1462\n",
       "    ],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.1370801919122687,\n",
       "    \"unexpected_percent_nonmissing\": 0.1370801919122687,\n",
       "    \"partial_unexpected_index_list\": null,\n",
       "    \"partial_unexpected_counts\": [\n",
       "      {\n",
       "        \"value\": 1462,\n",
       "        \"count\": 2\n",
       "      }\n",
       "    ]\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here is the summary for the failed expectation\n",
    "results_bad_data_checkpoint['run_results'][bad_data_run_identifier]['validation_result']['results'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pydatalondon2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6a19c996a27d3bf996916365ad2336703eb6dad2b2633101ec37e82813581f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
